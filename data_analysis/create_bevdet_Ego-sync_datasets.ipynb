{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "os.chdir(parent_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Ego-sync datasets for BEVDet\n",
    "\n",
    "We take Waymo as the reference dataset and transform ego frames of other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "argo_egoZ = [dict(type='EgoTranslate', trans = [-0.75,0,-0.3488])]\n",
    "kitti_egoZ = [dict(type='EgoTranslate', trans = [-3.0,0,-1.73])]\n",
    "K360_egoZ = [dict(type='EgoTranslate', trans = [-3.0,0,-1.73])]\n",
    "nusc_egoZ = [dict(type='ego_transform'), dict(type='EgoTranslate', trans = [-1.0,0,0])]\n",
    "lyft_egoZ = [dict(type='ego_transform'), dict(type='EgoTranslate', trans = [-2.0,0,0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "from mmdet3d.structures import LiDARInstance3DBoxes,CameraInstance3DBoxes\n",
    "import mmengine\n",
    "argo = ['data/argo2/argo2_infos_val_2Hz_part_mono_front.pkl','data/argo2/argo2_infos_train_2Hz_mono_front.pkl']\n",
    "kitti = ['data/kitti/kitti_infos_val.pkl','data/kitti/kitti_infos_train.pkl']\n",
    "K360 = ['data/kitti-360/kitti360_infos_val.pkl','data/kitti-360/kitti360_infos_train.pkl']\n",
    "nusc = ['data/nus_v2/nuscenes_infos_val_part_mono_front.pkl','data/nus_v2/nuscenes_infos_train_mono_front.pkl']\n",
    "lyft = ['data/lyft/lyft_infos_val_mono_front.pkl', 'data/lyft/lyft_infos_train_mono_front.pkl']\n",
    "pkl = nusc[0]\n",
    "infos = pandas.read_pickle(pkl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: nuScenes and Lyft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with data/nus_v2/nuscenes_infos_val_part_mono_front.pkl\n",
      "done with data/nus_v2/nuscenes_infos_train_mono_front.pkl\n",
      "done with data/lyft/lyft_infos_val_mono_front.pkl\n",
      "done with data/lyft/lyft_infos_train_mono_front.pkl\n"
     ]
    }
   ],
   "source": [
    "# nusc_egoZ = [dict(type='ego_transform'), dict(type='EgoTranslate', trans = [-1.0,0,0])]\n",
    "# lyft_egoZ = [dict(type='ego_transform'), dict(type='EgoTranslate', trans = [-2.0,0,0])]  \n",
    "ts = np.array([[-1.0,0,0],[-2.0,0,0]])\n",
    "for t, datasets in zip(ts,[nusc,lyft]):\n",
    "    for ds in datasets:\n",
    "        infos = pandas.read_pickle(ds)\n",
    "        for info in infos['data_list']:\n",
    "            # what to change: instances, cam2ego, lidar2cam, ego2global, lidar2ego\n",
    "            Tr1 = np.array(info['lidar_points']['lidar2ego'])\n",
    "            Tr2 = np.identity(4)\n",
    "            Tr2[:3,3] = -t\n",
    "            Tr = Tr1 @ Tr2\n",
    "            inv_Tr = np.linalg.inv(Tr)\n",
    "\n",
    "            bboxes = [inst['bbox_3d'] for inst in info['instances']]\n",
    "            gt_bbox_3d= LiDARInstance3DBoxes(np.array(bboxes),box_dim=7,origin=(0.5, 0.5, 0.5))\n",
    "            gt_bbox_3d.rotate(Tr[:3,:3].T)\n",
    "            gt_bbox_3d.translate(Tr[:3,3])\n",
    "            xyz, lwh, yaw= gt_bbox_3d.gravity_center.tolist(), gt_bbox_3d.dims.tolist(), gt_bbox_3d.yaw.tolist()\n",
    "            for i in range(len(info['instances'])):\n",
    "                info['instances'][i]['bbox_3d'] = [*xyz[i],*lwh[i],yaw[i]]\n",
    "\n",
    "            e2g = info['ego2global']\n",
    "            c2e = info['images']['CAM_FRONT']['cam2ego']\n",
    "            l2c = info['images']['CAM_FRONT']['lidar2cam']\n",
    "            info['images']['CAM_FRONT']['lidar2cam'] = (np.array(l2c) @ inv_Tr).tolist()\n",
    "            info['images']['CAM_FRONT']['cam2ego'] = (Tr @ np.array(c2e)).tolist()\n",
    "            info['ego2global'] = (np.array(e2g) @ inv_Tr).tolist()\n",
    "        mmengine.dump(infos,ds.replace('.pkl','_egoalign.pkl'))\n",
    "        print('done with', ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2: argoverse2, KITTI360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with data/argo2/argo2_infos_val_2Hz_part_mono_front.pkl\n",
      "done with data/argo2/argo2_infos_train_2Hz_mono_front.pkl\n",
      "done with data/kitti-360/kitti360_infos_val.pkl\n",
      "done with data/kitti-360/kitti360_infos_train.pkl\n"
     ]
    }
   ],
   "source": [
    "# argo_egoZ = [dict(type='EgoTranslate', trans = [-0.75,0,-0.3488])]\n",
    "# K360_egoZ = [dict(type='EgoTranslate', trans = [-3.0,0,-1.73])]\n",
    "ts = np.array([[-0.75,0,-0.3488],[-3.0,0,-1.73]])\n",
    "\n",
    "for t, datasets,CAM_FRONT in zip(ts,[argo,K360],['ring_front_center','CAM0']):\n",
    "    for ds in datasets:\n",
    "        infos = pandas.read_pickle(ds)\n",
    "        for info in infos['data_list']:\n",
    "            # what to change: instances, lidar2cam\n",
    "            # what ignore: ego2global\n",
    "            # what does not exist: cam2ego\n",
    "            Tr1 = np.identity(4)\n",
    "            Tr2 = np.identity(4)\n",
    "            Tr2[:3,3] = -t\n",
    "            Tr = Tr1 @ Tr2\n",
    "            inv_Tr = np.linalg.inv(Tr)\n",
    "            # print(info['instances'])\n",
    "            bboxes = [inst['bbox_3d'] for inst in info['instances']]\n",
    "            gt_bbox_3d= LiDARInstance3DBoxes(np.array(bboxes),box_dim=7,origin=(0.5, 0.5, 0.5))\n",
    "\n",
    "            gt_bbox_3d.rotate(Tr[:3,:3].T)\n",
    "            gt_bbox_3d.translate(Tr[:3,3])\n",
    "            xyz, lwh, yaw= gt_bbox_3d.gravity_center.tolist(), gt_bbox_3d.dims.tolist(), gt_bbox_3d.yaw.tolist()\n",
    "            for i in range(len(info['instances'])):\n",
    "                info['instances'][i]['bbox_3d'] = [*xyz[i],*lwh[i],yaw[i]]\n",
    "            # print(info['instances'])\n",
    "            l2c = info['images'][CAM_FRONT]['lidar2cam']\n",
    "            info['images'][CAM_FRONT]['lidar2cam'] = (np.array(l2c) @ inv_Tr).tolist()\n",
    "            # break\n",
    "        mmengine.dump(infos,ds.replace('.pkl','_egoalign.pkl'))\n",
    "        print('done with', ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3: KITTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with data/kitti/kitti_infos_val.pkl\n",
      "done with data/kitti/kitti_infos_train.pkl\n"
     ]
    }
   ],
   "source": [
    "# argo_egoZ = [dict(type='EgoTranslate', trans = [-0.75,0,-0.3488])]\n",
    "# K360_egoZ = [dict(type='EgoTranslate', trans = [-3.0,0,-1.73])]\n",
    "ts = np.array([-3.0,0,-1.73])\n",
    "# from mmdet3d.structures.bbox_3d import box_3d_mode\n",
    "LIDAR = 0\n",
    "CAM = 1\n",
    "DEPTH = 2\n",
    "for t, datasets,CAM_FRONT in zip([ts],[kitti],['CAM2']):\n",
    "    for ds in datasets:\n",
    "        infos = pandas.read_pickle(ds)\n",
    "        for info in infos['data_list']:\n",
    "            # what to change: instances, lidar2cam\n",
    "            # what ignore: ego2global\n",
    "            # what does not exist: cam2ego\n",
    "            Tr1 = np.identity(4)\n",
    "            Tr2 = np.identity(4)\n",
    "            Tr2[:3,3] = -t\n",
    "            Tr = Tr1 @ Tr2\n",
    "            inv_Tr = np.linalg.inv(Tr)\n",
    "            l2c = info['images'][CAM_FRONT]['lidar2cam']\n",
    "            # bboxes = [inst['bbox_3d'] for inst in info['instances']]\n",
    "            # gt_bbox_3d= LiDARInstance3DBoxes(np.array(bboxes),box_dim=7,origin=(0.5, 0.5, 0.5))\n",
    "            # gt_bbox_3d = CameraInstance3DBoxes(np.array(bboxes))\n",
    "            # gt_bbox_3d = gt_bbox_3d.convert_to(LIDAR, np.linalg.inv(l2c))\n",
    "            # gt_bbox_3d.rotate(Tr[:3,:3].T)\n",
    "            # gt_bbox_3d.translate(Tr[:3,3])\n",
    "            # gt_bbox_3d = gt_bbox_3d.convert_to(CAM, l2c)\n",
    "            # xyz, lwh, yaw= gt_bbox_3d.gravity_center.tolist(), gt_bbox_3d.dims.tolist(), gt_bbox_3d.yaw.tolist()\n",
    "            # for i in range(len(info['instances'])):\n",
    "            #     info['instances'][i]['bbox_3d'] = [*xyz[i],*lwh[i],yaw[i]]\n",
    "            info['images'][CAM_FRONT]['lidar2cam'] = (np.array(l2c) @ inv_Tr).tolist()\n",
    "        mmengine.dump(infos,ds.replace('.pkl','_egoalign.pkl'))\n",
    "        print('done with', ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(infos['data_list'][0].keys())\n",
    "print(infos['data_list'][0]['images']['CAM_FRONT'].keys())\n",
    "print(infos['data_list'][0]['ego2global'])\n",
    "print(infos['data_list'][0]['images']['CAM_FRONT']['cam2ego'])\n",
    "print(infos['data_list'][0]['images']['CAM_FRONT']['lidar2cam'])\n",
    "print(infos['data_list'][0]['instances'][0])\n",
    "print(infos['data_list'][1]['token'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['sample_idx', 'log_id', 'city_name', 'timestamp', 'ego2global', 'images', 'lidar_points', 'instances'])\n",
      "dict_keys(['sample_idx', 'images', 'lidar_points', 'instances', 'cam_instances'])\n",
      "dict_keys(['sample_idx', 'log_id', 'timestamp', 'cam0_to_global', 'images', 'lidar_points', 'instances'])\n",
      "dict_keys(['sample_idx', 'token', 'timestamp', 'ego2global', 'images', 'lidar_points', 'instances', 'city_name'])\n",
      "dict_keys(['sample_idx', 'token', 'timestamp', 'ego2global', 'images', 'lidar_points', 'lidar_sweeps', 'instances', 'city_name'])\n"
     ]
    }
   ],
   "source": [
    "for datasets in [argo,kitti,K360,nusc,lyft]:\n",
    "    for ds in datasets:\n",
    "        infos = pandas.read_pickle(ds)\n",
    "        print(infos['data_list'][0].keys())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['num_pts_feats', 'lidar_path', 'lidar2ego_down', 'lidar2ego_up', 'timestamp'])\n",
      "dict_keys(['num_pts_feats', 'lidar_path', 'Tr_velo_to_cam', 'Tr_imu_to_velo'])\n",
      "dict_keys(['num_pts_feats', 'lidar_path', 'lidar2ego', 'timestamp'])\n",
      "dict_keys(['num_pts_feats', 'lidar_path', 'lidar2ego'])\n",
      "dict_keys(['num_pts_feats', 'lidar_path', 'lidar2ego'])\n"
     ]
    }
   ],
   "source": [
    "for datasets in [argo,kitti,K360,nusc,lyft]:\n",
    "    for ds in datasets:\n",
    "        infos = pandas.read_pickle(ds)\n",
    "        print(infos['data_list'][0]['lidar_points'].keys())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ring_front_center'])\n",
      "dict_keys(['CAM0', 'CAM1', 'CAM2', 'CAM3', 'R0_rect'])\n",
      "dict_keys(['CAM0', 'CAM1'])\n",
      "dict_keys(['CAM_FRONT'])\n",
      "dict_keys(['CAM_FRONT'])\n"
     ]
    }
   ],
   "source": [
    "for datasets in [argo,kitti,K360,nusc,lyft]:\n",
    "    for ds in datasets:\n",
    "        infos = pandas.read_pickle(ds)\n",
    "        print(infos['data_list'][0]['images'].keys())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['img_path', 'height', 'width', 'cam2img', 'lidar2cam', 'timestamp'])\n",
      "dict_keys(['img_path', 'height', 'width', 'cam2img', 'lidar2img', 'lidar2cam'])\n",
      "dict_keys(['img_path', 'height', 'width', 'cam2img', 'lidar2cam', 'timestamp'])\n",
      "dict_keys(['img_path', 'cam2img', 'cam2ego', 'sample_data_token', 'timestamp', 'lidar2cam'])\n",
      "dict_keys(['img_path', 'cam2img', 'cam2ego', 'sample_data_token', 'timestamp', 'lidar2cam'])\n"
     ]
    }
   ],
   "source": [
    "for i,datasets in zip(['ring_front_center','CAM2','CAM0','CAM_FRONT','CAM_FRONT'],[argo,kitti,K360,nusc,lyft]):\n",
    "    for ds in datasets:\n",
    "        infos = pandas.read_pickle(ds)\n",
    "        print(infos['data_list'][0]['images'][i].keys())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.23  1.59  8.55  2.37  1.63  1.48 -1.47]\n",
      "LiDARInstance3DBoxes(\n",
      "    tensor([[ 3.2300,  1.5900,  7.8100,  2.3700,  1.6300,  1.4800, -1.4700]]))\n",
      "tensor([[3.2300, 1.5900, 8.5500]]) tensor([[2.3700, 1.6300, 1.4800]]) tensor([-1.4700])\n",
      "[[3.2300000190734863, 1.590000033378601, 8.550000190734863]] [[2.369999885559082, 1.6299999952316284, 1.4800000190734863]] [-1.4700000286102295]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mmdet3d.structures import LiDARInstance3DBoxes,CameraInstance3DBoxes\n",
    "import mmengine\n",
    "inst = infos['data_list'][1]['instances'][0]\n",
    "gt_bbox_3d = np.array(inst['bbox_3d'])\n",
    "print(gt_bbox_3d)\n",
    "gt_bbox_3d= LiDARInstance3DBoxes([gt_bbox_3d],box_dim=7,origin=(0.5, 0.5, 0.5))\n",
    "print(gt_bbox_3d)\n",
    "print(gt_bbox_3d.gravity_center,gt_bbox_3d.dims,gt_bbox_3d.yaw)\n",
    "print(gt_bbox_3d.gravity_center.tolist(),gt_bbox_3d.dims.tolist(),gt_bbox_3d.yaw.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# NOTE THAT WE ONLY CHANGE poses w.r.t CAM0 and instances! NO other poses changed\n",
    "# @TRANSFORMS.register_module()\n",
    "# class ego_transform:\n",
    "#     def __init__(self, trans='lidar2ego'):\n",
    "#         self.T = trans\n",
    "#     def transformation(self,results, Tr):\n",
    "#         Tr = np.array(results['lidar_points'][self.T])\n",
    "#         inv_Tr = np.linalg.inv(Tr)\n",
    "#         results['gt_bboxes_3d'].rotate(Tr[:3,:3].T) # LidarInstance.rotate use right-side matmul\n",
    "#         results['gt_bboxes_3d'].translate(Tr[:3,3])\n",
    "#         results['lidar2cam'] = np.array(results['lidar2cam']) @ inv_Tr # @ pt_new\n",
    "#         trans = results.get('trans_mat',np.identity(4))\n",
    "#         results['trans_mat'] = Tr @ trans # @ pt_origin\n",
    "#         return results\n",
    "\n",
    "# @TRANSFORMS.register_module()\n",
    "# class EgoTranslate:\n",
    "#         new2old = np.identity(4)\n",
    "#         new2old[:3,3] = t\n",
    "#         old2new = np.identity(4)\n",
    "#         old2new[:3,3] = -t\n",
    "#         results['gt_bboxes_3d'].translate(-t)\n",
    "#         results['lidar2cam'] = np.array(results['lidar2cam']) @ new2old # @ pt_new\n",
    "#         trans = results.get('trans_mat',np.identity(4))\n",
    "#         results['trans_mat'] = old2new @ trans # @ pt_origin\n",
    "#         # return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmdev11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
