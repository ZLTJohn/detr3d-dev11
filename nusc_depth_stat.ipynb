{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import mmengine\n",
    "# info = pandas.read_pickle('data/kitti-360/kitti360_infos_all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from projects.detr3d.custom_concat_dataset import CustomNusc\n",
    "from projects.configs import debug\n",
    "import copy\n",
    "from mmdet3d.utils import register_all_modules, replace_ceph_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/16 11:32:03 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - ------------------------------\n",
      "04/16 11:32:03 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - The length of the dataset: 34149\n",
      "04/16 11:32:03 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - The number of instances per category in the dataset:\n",
      "+----------------------+--------+\n",
      "| category             | number |\n",
      "+----------------------+--------+\n",
      "| car                  | 493322 |\n",
      "| truck                | 88519  |\n",
      "| construction_vehicle | 14671  |\n",
      "| bus                  | 16321  |\n",
      "| trailer              | 24860  |\n",
      "| motorcycle           | 12617  |\n",
      "| bicycle              | 11859  |\n",
      "| pedestrian           | 220194 |\n",
      "+----------------------+--------+\n"
     ]
    }
   ],
   "source": [
    "register_all_modules()\n",
    "cfg = copy.deepcopy(debug.nusc_val)\n",
    "cfg['ann_file'] = 'nuscenes_infos_trainval.pkl'\n",
    "cfg['data_root'] = 'data/nus_v2/'\n",
    "cfg.pop('type')\n",
    "cfg.pop('load_interval',None)\n",
    "dataset = CustomNusc(**cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/16 11:06:37 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - ------------------------------\n",
      "04/16 11:06:37 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - The length of the dataset: 34149\n",
      "04/16 11:06:37 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - The number of instances per category in the dataset:\n",
      "+----------------------+--------+\n",
      "| category             | number |\n",
      "+----------------------+--------+\n",
      "| car                  | 493322 |\n",
      "| truck                | 88519  |\n",
      "| construction_vehicle | 14671  |\n",
      "| bus                  | 16321  |\n",
      "| trailer              | 24860  |\n",
      "| motorcycle           | 12617  |\n",
      "| bicycle              | 11859  |\n",
      "| pedestrian           | 220194 |\n",
      "+----------------------+--------+\n"
     ]
    }
   ],
   "source": [
    "register_all_modules()\n",
    "cfg = copy.deepcopy(debug.nusc_val)\n",
    "cfg['ann_file'] = 'nuscenes_infos_trainval.pkl'\n",
    "cfg['data_root'] = 'data/nus_v2/'\n",
    "cfg.pop('type')\n",
    "cfg.pop('load_interval',None)\n",
    "dataset = CustomNusc(**cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "Loading nuScenes-lidarseg...\n",
      "32 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "34149 lidarseg,\n",
      "Done loading in 83.588 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 20.6 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "from nuscenes import NuScenes\n",
    "nusc = NuScenes('v1.0-trainval','data/nuscenes/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from projects.detr3d.vis_zlt import visualizer_zlt\n",
    "from projects.detr3d.detr3d import DETR3D\n",
    "import os.path as osp\n",
    "import os\n",
    "import numpy as np\n",
    "from projects.detr3d.detr3d import DETR3D\n",
    "import torch\n",
    "from mmdet3d.structures import LiDARInstance3DBoxes\n",
    "from mmengine.structures import InstanceData\n",
    "detr3d = DETR3D()\n",
    "token2idx = pandas.read_pickle('debug/lyc_map/token2idx_trainval.pkl')\n",
    "vis = visualizer_zlt(debug_name='',vis_count=10000, draw_score_type = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_frame(token, map_points):\n",
    "    idx = token2idx[token]\n",
    "    frame = dataset[idx]\n",
    "    kpts= map_points\n",
    "    trans = [ 646.2525, 1612.6713,    1.8371]# should be lidar2ego but not 2global\n",
    "    # kpts = np.load('/home/zhenglt/mmdev11/detr3d-dev11/debug/0a0d6b8c2e884134a3b48df43d54c36a.npy')\n",
    "    kpts_3d = np.zeros((kpts.shape[0],7))\n",
    "    gt_labels_3d = torch.zeros((kpts.shape[0]))\n",
    "    if kpts.shape[-1] == 2:\n",
    "        kpts_3d[:,:2] = kpts\n",
    "        kpts_3d[:,2] -= trans[-1]\n",
    "    else:\n",
    "        kpts_3d[:,:3] = kpts\n",
    "    gt_bboxes_3d = LiDARInstance3DBoxes(torch.tensor(kpts_3d),box_dim=7,origin=(0.5,0.5,0.5))\n",
    "    map_inst = vis.toInstance({'gt_bboxes_3d': gt_bboxes_3d, 'gt_labels_3d': gt_labels_3d}, device=gt_labels_3d.device)\n",
    "    name = osp.basename(frame['data_samples'].lidar_path).split('.')[0]\n",
    "    inst = frame['data_samples'].gt_instances_3d[:2]\n",
    "    gt_bboxes_3d = inst.bboxes_3d\n",
    "    print(name)\n",
    "    # vis.visualize(inst, batch_input_metas,None,'test','debug/')\n",
    "    cat_instances = InstanceData.cat([map_inst, vis.add_score(frame['data_samples'].gt_instances_3d)])\n",
    "    if not osp.exists('debug/lyc_map/'+token):\n",
    "        os.mkdir('debug/lyc_map/'+token)\n",
    "    vis.visualize_dataset_item(frame,[cat_instances],pts = None,name_suffix='debug_pred', dirname='debug/lyc_map/'+token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANGE = 102.4\n",
    "def filter_pts_inrange(pts):\n",
    "        max_x = RANGE / 2\n",
    "        max_y = RANGE / 2\n",
    "        mask = (-max_x < pts[...,0]) & (pts[..., 0] < max_x) & \\\n",
    "               (-max_y < pts[...,1]) & (pts[..., 1] < max_y)\n",
    "        pts = pts[mask]\n",
    "        # return none if nothing\n",
    "        return pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save to debug/depth_stat/CAM_FRONT\n",
      "save to debug/depth_stat/CAM_FRONT_RIGHT\n",
      "save to debug/depth_stat/CAM_FRONT_LEFT\n",
      "save to debug/depth_stat/CAM_BACK\n",
      "save to debug/depth_stat/CAM_BACK_LEFT\n",
      "save to debug/depth_stat/CAM_BACK_RIGHT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from projects.detr3d.detr3d_featsampler import DefaultFeatSampler\n",
    "import mmengine\n",
    "feat_samp = DefaultFeatSampler()\n",
    "depths = [[],[],[],[],[],[]]\n",
    "for i in range(0,len(dataset),5):\n",
    "    frame = dataset[i]\n",
    "    pts = torch.tensor(np.fromfile(frame['data_samples'].metainfo['lidar_path'], dtype=np.float32).reshape(-1,5))[:,:3]\n",
    "    pts = filter_pts_inrange(pts)\n",
    "    batch_input_metas = [frame['data_samples'].metainfo]\n",
    "    batch_input_metas = vis.add_lidar2img(batch_input_metas)\n",
    "    batch_input_metas[0]['pad_shape'] = 900, 1600\n",
    "    pt_cam, mask, depth= feat_samp.project_ego2cam(pts.view(1, -1, 3),debug.point_cloud_range, batch_input_metas, return_depth=True)\n",
    "    pt_cam = pt_cam.squeeze(0)\n",
    "    mask = mask.squeeze(0).squeeze(-1)  # [cam, gt]\n",
    "    depth = depth.squeeze(0)\n",
    "    pts = torch.cat((pts, torch.ones_like(pts[..., :1])), -1)\n",
    "    for cam in range(depth.shape[0]):\n",
    "        # depth_i = depth[cam][mask[cam]]\n",
    "        lidar2cam_i = batch_input_metas[0]['lidar2cam'][cam]\n",
    "        pts_cami = torch.matmul(torch.tensor(lidar2cam_i), pts.T)\n",
    "        depth_i = pts_cami[2][mask[cam]]\n",
    "        # print(depth_i.shape)\n",
    "        # TODO: debug why there are so many negetive points\n",
    "        depths[cam].append(depth_i)\n",
    "mmengine.dump(depths, 'debug/depth_stat/depths.pkl')\n",
    "cam_name = list(debug.nusc_data_prefix.keys())\n",
    "cam_name.remove('pts')\n",
    "cam_name.remove('sweeps')\n",
    "import matplotlib.pyplot as plt\n",
    "for depth,name in zip(depths,cam_name):\n",
    "    depth = torch.cat(depth) \n",
    "    depth = np.array(depth)\n",
    "    plt.hist(depth,bins = 10)\n",
    "    plt.savefig('debug/depth_stat/'+name)\n",
    "    print('save to '+'debug/depth_stat/'+name)\n",
    "    plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lane_divider': [<shapely.geometry.linestring.LineString object at 0x2b6d0ddfc100>, <shapely.geometry.linestring.LineString object at 0x2b6d0ddfc5b0>, <shapely.geometry.linestring.LineString object at 0x2b6d0ddfcb50>, <shapely.geometry.linestring.LineString object at 0x2b6d0ddfcc70>, <shapely.geometry.linestring.LineString object at 0x2b6d0ddfc190>, <shapely.geometry.linestring.LineString object at 0x2b6d0ddfc4c0>, <shapely.geometry.linestring.LineString object at 0x2b6d0ddfcfd0>, <shapely.geometry.linestring.LineString object at 0x2b6d9dc59ac0>, <shapely.geometry.linestring.LineString object at 0x2b6d02e34fa0>, <shapely.geometry.linestring.LineString object at 0x2b6d9dc59ee0>], 'lane': [<shapely.geometry.multipolygon.MultiPolygon object at 0x2b6d0ddfc070>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6d0ddfcfa0>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6d02e34f70>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6de9c06a30>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6d1dd78a30>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6d02e34e50>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6d02e34ee0>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6b03c6cb20>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6b03c6c7f0>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6d02e34f40>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6d02e34eb0>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6b03c6ca00>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6b03c6c2b0>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6d8d18eb50>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6d8d18e460>], 'road_divider': [<shapely.geometry.linestring.LineString object at 0x2b6d8d18e250>, <shapely.geometry.linestring.LineString object at 0x2b6d8d18e640>, <shapely.geometry.linestring.LineString object at 0x2b6d8d18e0d0>], 'road_segment': [<shapely.geometry.multipolygon.MultiPolygon object at 0x2b6d02e34fd0>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6d8d18e580>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6d8d18e9d0>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6d8d18e490>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6d8d18e130>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6d8d18e790>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6d8d18eb20>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6d8d18edf0>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6d8d18e100>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6d8d18e070>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6d8d18e3a0>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6d8d18e160>], 'ped_crossing': [<shapely.geometry.multipolygon.MultiPolygon object at 0x2b6d8d18e880>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6d8d18e190>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6d8d18e6a0>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6d8d18e7c0>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6d8d18e910>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6d8d18e2b0>, <shapely.geometry.multipolygon.MultiPolygon object at 0x2b6d8d18e550>]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34154/3560806371.py:24: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  gt_list = nusc_map(((*center_xy,*size_xy), yaw, location))\n",
      "/tmp/ipykernel_34154/2320943453.py:117: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for _g in g:\n",
      "/home/zhenglt/mmdev11/detr3d-dev11/projects/detr3d/vis_zlt.py:150: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(instances_3d['gt_labels_3d']).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n008-2018-09-18-14-35-12-0400__LIDAR_TOP__1537295816397605\n",
      "reference torch.Size([2169, 3])\n",
      "900 1600\n",
      "torch.Size([1, 2168, 3])\n",
      "frame: 30925\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nusc_map = VectorizeLocalMap(data_root='data/nuscenes/')\n",
    "map_data = pandas.read_pickle('debug/lyc_map/map_data_upsampling.pkl')\n",
    "for token in map_data:\n",
    "    idx = token2idx[token]\n",
    "    if token != 'a08cf86f5b2a4f5abdee5756820aa66f':\n",
    "        continue\n",
    "    frame = dataset[idx]\n",
    "    location = frame['data_samples'].metainfo['city_name']\n",
    "    # patch_box = \n",
    "    from pyquaternion import Quaternion\n",
    "    e2g = np.array(frame['data_samples'].metainfo['ego2global'])\n",
    "    rot = Quaternion(matrix=e2g[:3,:3],atol=1e-5)\n",
    "    yaw = rot.yaw_pitch_roll[0] /np.pi *180\n",
    "    center_xy = e2g[:2,3]\n",
    "    size_xy = [100,100]\n",
    "    gt_list = nusc_map(((*center_xy,*size_xy), yaw, location))\n",
    "    l2e = np.array(frame['data_samples'].metainfo['lidar2ego'])\n",
    "    e2l = torch.tensor(np.linalg.inv(l2e))\n",
    "    map_points = []\n",
    "    for gt in gt_list:\n",
    "        map_points.append(torch.tensor(gt))\n",
    "    map_points = torch.cat(map_points)\n",
    "    map_z = torch.zeros_like(map_points[:,0:1])\n",
    "    map_t = torch.ones_like(map_points[:,0:1])\n",
    "    map_points = torch.cat([map_points, map_z, map_t],dim=-1)\n",
    "    e2g_conpensate = Quaternion(axis=[0, 1, 0], radians=rot.yaw_pitch_roll[1]) * Quaternion(axis=[1, 0, 0], radians=rot.yaw_pitch_roll[2])\n",
    "    e2g_R = e2g_conpensate.rotation_matrix\n",
    "    g2e_R = np.linalg.inv(e2g_R)\n",
    "    g2e_R4d = np.identity(4)\n",
    "    g2e_R4d[:3,:3] = g2e_R\n",
    "    map_points = torch.matmul(torch.tensor(g2e_R4d),map_points.T).T\n",
    "    map_points = torch.matmul(e2l,map_points.T).T\n",
    "    # print(filter_pts_inrange(map_points))\n",
    "    # print(map_points[:,:3])\n",
    "    # break\n",
    "    view_frame(token, map_points[:,:3])\n",
    "    # break\n",
    "    # print(np.array(Quaternion(matrix=l2e[:3,:3],atol=1e-5).yaw_pitch_roll)/np.pi*180)\n",
    "    # print(np.array(rot.yaw_pitch_roll)/np.pi*180)\n",
    "    # break\n",
    "    \n",
    "\n",
    "# lidar_token = nusc.get('sample',token)['data']['LIDAR_TOP']\n",
    "# ego = nusc.get('sample_data',lidar_token)['ego_pose_token']\n",
    "# ego_pose = nusc.get('ego_pose',ego)\n",
    "# nusc_e2gR = Quaternion(ego_pose['rotation']).rotation_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:234: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:264: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:311: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:234: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:264: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:311: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/tmp/ipykernel_34154/2320943453.py:234: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if new_polygon.geom_type is 'Polygon':\n",
      "/tmp/ipykernel_34154/2320943453.py:264: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if new_polygon.geom_type is 'Polygon':\n",
      "/tmp/ipykernel_34154/2320943453.py:311: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if layer_name is 'traffic_light':\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.patches import Arrow, Rectangle\n",
    "from matplotlib.patches import Polygon as mPolygon\n",
    "from nuscenes.map_expansion.bitmap import BitMap\n",
    "from nuscenes.map_expansion.map_api import NuScenesMapExplorer\n",
    "from shapely import affinity\n",
    "from shapely.geometry import Polygon, MultiPolygon, LineString, Point, box\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "from nuscenes.map_expansion.map_api import NuScenesMap, NuScenesMapExplorer\n",
    "from nuscenes.eval.common.utils import quaternion_yaw, Quaternion\n",
    "\n",
    "\n",
    "class VectorizeLocalMap(object):\n",
    "\n",
    "    def __init__(self,\n",
    "                 data_root=\"./datasets/nuScenes/\",\n",
    "                 line_classes=['road_divider', 'lane_divider'],\n",
    "                 ped_crossing_classes=['ped_crossing'],\n",
    "                 contour_classes=['road_segment', 'lane'],\n",
    "                 **kwargs):\n",
    "        '''\n",
    "        Args:\n",
    "            fixed_num = -1 : no fixed num\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.data_root = data_root\n",
    "        self.MAPS = ['boston-seaport', 'singapore-hollandvillage',\n",
    "                     'singapore-onenorth', 'singapore-queenstown']\n",
    "        self.line_classes = line_classes\n",
    "        self.ped_crossing_classes = ped_crossing_classes\n",
    "        self.contour_classes = contour_classes\n",
    "\n",
    "        self.nusc_maps = {}\n",
    "        self.map_explorer = {}\n",
    "        for loc in self.MAPS:\n",
    "            self.nusc_maps[loc] = NuScenesMap(\n",
    "                dataroot=self.data_root, map_name=loc)\n",
    "            self.map_explorer[loc] = NuScenesMapExplorer(self.nusc_maps[loc])\n",
    "\n",
    "    def retrive_geom(self, patch_params):\n",
    "        '''\n",
    "            Get the geometric data.\n",
    "            Returns: dict\n",
    "        '''\n",
    "        patch_box, patch_angle, location = patch_params\n",
    "        geoms_dict = {}\n",
    "        centerline_records = []\n",
    "\n",
    "        layers = \\\n",
    "            self.line_classes + self.ped_crossing_classes + \\\n",
    "            self.contour_classes\n",
    "\n",
    "        layers = set(layers)\n",
    "        for layer_name in layers:\n",
    "\n",
    "            return_token = False\n",
    "\n",
    "            # retrive the geo\n",
    "            if layer_name in self.nusc_maps[location].non_geometric_line_layers:\n",
    "                geoms = self.map_explorer[location]._get_layer_line(\n",
    "                    patch_box, patch_angle, layer_name)\n",
    "            elif layer_name in self.nusc_maps[location].lookup_polygon_layers:\n",
    "                geoms = self.map_explorer[location]._get_layer_polygon(\n",
    "                    patch_box, patch_angle, layer_name)\n",
    "            else:\n",
    "                raise ValueError('{} is not a valid layer'.format(layer_name))\n",
    "\n",
    "            if geoms is None:\n",
    "                continue\n",
    "\n",
    "            # change every geoms set to list\n",
    "            if not isinstance(geoms, list):\n",
    "                geoms = [geoms, ]\n",
    "\n",
    "            geoms_dict[layer_name] = geoms\n",
    "\n",
    "        return geoms_dict\n",
    "\n",
    "    # def get_global_patch(self, input_dict: dict):\n",
    "    #     # transform to global coordination\n",
    "    #     location = input_dict['location']\n",
    "    #     translation = input_dict['ego2global_translation']\n",
    "    #     rotation = Quaternion(\n",
    "    #         input_dict['ego2global_rotation']).rotation_matrix\n",
    "    #     lidar2ego_translation = input_dict['lidar2ego_translation']\n",
    "    #     lidar2ego_rotation = Quaternion(\n",
    "    #         input_dict['lidar2ego_rotation']).rotation_matrix\n",
    "\n",
    "    #     rotation = rotation @ lidar2ego_rotation  # [3, 3]patch_box\n",
    "    #     patch_box = (map_pose[0], map_pose[1],\n",
    "    #                  self.patch_size[0], self.patch_size[1])\n",
    "    #     patch_angle = quaternion_yaw(rotation) / np.pi * 180\n",
    "\n",
    "    #     patch_params = (patch_box, patch_angle, location)\n",
    "    #     return patch_params\n",
    "\n",
    "    def __call__(self, patch_params):\n",
    "\n",
    "        geoms_dict = self.retrive_geom(patch_params)\n",
    "        print(geoms_dict)\n",
    "        def sample_pts(pts):\n",
    "            line = LineString(pts)\n",
    "            distances = list(np.arange(1.0,\n",
    "                                       line.length, 1.0))\n",
    "            sampled_points = np.array([list(line.interpolate(distance).coords)\n",
    "                                       for distance in distances]).reshape(-1, 2)\n",
    "            return sampled_points\n",
    "\n",
    "        kpts = []\n",
    "        for k in geoms_dict:\n",
    "            for g in geoms_dict[k]:\n",
    "                if 'Polygon' in g.type:\n",
    "                    if 'Multi' in g.type:\n",
    "                        for _g in g:\n",
    "                            kpts.append(np.array(_g.exterior))\n",
    "                            kpts[-1] = sample_pts(kpts[-1])\n",
    "                    else:\n",
    "                        kpts.append(np.array(g.exterior))\n",
    "                        kpts[-1] = sample_pts(kpts[-1])\n",
    "                else:\n",
    "                    kpts.append(np.array(g))\n",
    "                    kpts[-1] = sample_pts(kpts[-1])\n",
    "\n",
    "        return kpts\n",
    "\n",
    "\n",
    "class CNuScenesMapExplorer(NuScenesMapExplorer):\n",
    "    def __ini__(self, *args, **kwargs):\n",
    "        super(self, CNuScenesMapExplorer).__init__(*args, **kwargs)\n",
    "\n",
    "    def render_map_patch(self,\n",
    "                         box_coords: Tuple[float, float, float, float],\n",
    "                         layer_names: List[str] = None,\n",
    "                         alpha: float = 0.5,\n",
    "                         figsize: Tuple[float, float] = (15, 15),\n",
    "                         render_egoposes_range: bool = True,\n",
    "                         render_legend: bool = True,\n",
    "                         bitmap: Optional[BitMap] = None) -> Tuple[Figure, Axes]:\n",
    "        \"\"\"\n",
    "        Renders a rectangular patch specified by `box_coords`. By default renders all layers.\n",
    "        :param box_coords: The rectangular patch coordinates (x_min, y_min, x_max, y_max).\n",
    "        :param layer_names: All the non geometric layers that we want to render.\n",
    "        :param alpha: The opacity of each layer.\n",
    "        :param figsize: Size of the whole figure.\n",
    "        :param render_egoposes_range: Whether to render a rectangle around all ego poses.\n",
    "        :param render_legend: Whether to render the legend of map layers.\n",
    "        :param bitmap: Optional BitMap object to render below the other map layers.\n",
    "        :return: The matplotlib figure and axes of the rendered layers.\n",
    "        \"\"\"\n",
    "        x_min, y_min, x_max, y_max = box_coords.bounds\n",
    "\n",
    "        if layer_names is None:\n",
    "            layer_names = self.map_api.non_geometric_layers\n",
    "\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "\n",
    "        local_width = x_max - x_min\n",
    "        local_height = y_max - y_min\n",
    "        assert local_height > 0, 'Error: Map patch has 0 height!'\n",
    "        local_aspect_ratio = local_width / local_height\n",
    "\n",
    "        ax = fig.add_axes([0, 0, 1, 1 / local_aspect_ratio])\n",
    "\n",
    "        if bitmap is not None:\n",
    "            bitmap.render(self.map_api.canvas_edge, ax)\n",
    "\n",
    "        for layer_name in layer_names:\n",
    "            self._render_layer(ax, layer_name, alpha)\n",
    "\n",
    "        x_margin = np.minimum(local_width / 4, 50)\n",
    "        y_margin = np.minimum(local_height / 4, 10)\n",
    "        ax.set_xlim(x_min - x_margin, x_max + x_margin)\n",
    "        ax.set_ylim(y_min - y_margin, y_max + y_margin)\n",
    "\n",
    "        if render_egoposes_range:\n",
    "            bbox = np.array(box_coords.exterior.coords)\n",
    "            WH = np.linalg.norm(bbox[1:3]-bbox[:2], axis=-1)\n",
    "            W, iw = max(WH), np.argmax(WH)\n",
    "            H, ih = min(WH), np.argmin(WH)\n",
    "\n",
    "            ax.add_patch(mPolygon(np.array(box_coords.exterior.coords), fill=False, linestyle='-.', color='red',\n",
    "                                  lw=2))\n",
    "            ax.text(bbox[ih:2+ih, 0].mean(), bbox[ih:2+ih, 1].mean(), \"%g m\" % H,\n",
    "                    fontsize=14, weight='bold')\n",
    "            ax.text(bbox[iw:2+iw, 0].mean(), bbox[iw:2+iw, 1].mean(), \"%g m\" % W,\n",
    "                    fontsize=14, weight='bold')\n",
    "\n",
    "        if render_legend:\n",
    "            ax.legend(frameon=True, loc='upper right')\n",
    "\n",
    "        return fig, ax\n",
    "\n",
    "    def _get_layer_polygon(self,\n",
    "                           patch_box: Tuple[float, float, float, float],\n",
    "                           patch_angle: float,\n",
    "                           layer_name: str,\n",
    "                           return_token: bool = False) -> Tuple[List[Polygon], Optional[List[str]]]:\n",
    "        \"\"\"\n",
    "         Retrieve the polygons of a particular layer within the specified patch.\n",
    "         :param patch_box: Patch box defined as [x_center, y_center, height, width].\n",
    "         :param patch_angle: Patch orientation in degrees.\n",
    "         :param layer_name: name of map layer to be extracted.\n",
    "         :return: List of Polygon in a patch box.\n",
    "         \"\"\"\n",
    "        if layer_name not in self.map_api.non_geometric_polygon_layers+['lane_connector']:\n",
    "            raise ValueError('{} is not a polygonal layer'.format(layer_name))\n",
    "\n",
    "        patch_x = patch_box[0]\n",
    "        patch_y = patch_box[1]\n",
    "\n",
    "        patch = self.get_patch_coord(patch_box, patch_angle)\n",
    "\n",
    "        records = getattr(self.map_api, layer_name)\n",
    "\n",
    "        polygon_list = []\n",
    "        polygon_tokens_list = []\n",
    "        valid_records = []\n",
    "        if layer_name == 'drivable_area':\n",
    "            for record in records:\n",
    "\n",
    "                for polygon_token in record['polygon_tokens']:\n",
    "\n",
    "                    polygon = self.map_api.extract_polygon(polygon_token)\n",
    "                    new_polygon = polygon.intersection(patch)\n",
    "\n",
    "                    if not new_polygon.is_empty:\n",
    "                        new_polygon = affinity.rotate(new_polygon, -patch_angle,\n",
    "                                                      origin=(patch_x, patch_y), use_radians=False)\n",
    "                        new_polygon = affinity.affine_transform(new_polygon,\n",
    "                                                                [1.0, 0.0, 0.0, 1.0, -patch_x, -patch_y])\n",
    "                        if new_polygon.geom_type is 'Polygon':\n",
    "                            new_polygon = MultiPolygon([new_polygon])\n",
    "                        polygon_list.append(new_polygon)\n",
    "                        polygon_tokens_list.append(polygon_token)\n",
    "        else:\n",
    "            for record in records:\n",
    "                if record['polygon_token'] is None:\n",
    "                    # import ipdb\n",
    "                    # ipdb.set_trace()\n",
    "                    continue\n",
    "                polygon = self.map_api.extract_polygon(record['polygon_token'])\n",
    "\n",
    "                # if polygon.intersects(patch) or polygon.within(patch):\n",
    "                #     if not polygon.is_valid:\n",
    "                #         print('within: {}, intersect: {}'.format(polygon.within(patch), polygon.intersects(patch)))\n",
    "                #         print('polygon token {} is_valid: {}'.format(record['polygon_token'], polygon.is_valid))\n",
    "\n",
    "                # polygon = polygon.buffer(0)\n",
    "\n",
    "                if polygon.is_valid:\n",
    "                    # if within or intersect :\n",
    "\n",
    "                    new_polygon = polygon.intersection(patch)\n",
    "                    # new_polygon = polygon\n",
    "\n",
    "                    if not new_polygon.is_empty:\n",
    "                        new_polygon = affinity.rotate(new_polygon, -patch_angle,\n",
    "                                                      origin=(patch_x, patch_y), use_radians=False)\n",
    "                        new_polygon = affinity.affine_transform(new_polygon,\n",
    "                                                                [1.0, 0.0, 0.0, 1.0, -patch_x, -patch_y])\n",
    "                        if new_polygon.geom_type is 'Polygon':\n",
    "                            new_polygon = MultiPolygon([new_polygon])\n",
    "                        polygon_list.append(new_polygon)\n",
    "                        polygon_tokens_list.append(record['polygon_token'])\n",
    "                        # print('polygon token accepeted:', record['polygon_token'])\n",
    "                        if layer_name in '(lane,road_block)':\n",
    "                            record['from_edge_line'] = \\\n",
    "                                to_patch_coord(self.map_api.extract_line(\n",
    "                                    record['from_edge_line_token']), patch_angle, patch_x, patch_y)\n",
    "                            record['to_edge_line'] = \\\n",
    "                                to_patch_coord(self.map_api.extract_line(\n",
    "                                    record['to_edge_line_token']), patch_angle, patch_x, patch_y)\n",
    "\n",
    "                        if layer_name in ['lane', 'lane_connector']:\n",
    "                            centerline = self.map_api.discretize_lanes(\n",
    "                                record, 0.5)\n",
    "                            centerline = list(self.map_api.discretize_lanes(\n",
    "                                [record['token']], 0.5).values())[0]\n",
    "                            centerline = LineString(\n",
    "                                np.array(centerline)[:, :2])\n",
    "                            centerline = centerline.intersection(patch)\n",
    "                            record['centerline'] = \\\n",
    "                                to_patch_coord(\n",
    "                                    centerline, patch_angle, patch_x, patch_y)\n",
    "\n",
    "                        valid_records.append(record)\n",
    "\n",
    "        if return_token:\n",
    "            return polygon_list, polygon_tokens_list, valid_records\n",
    "\n",
    "        return polygon_list\n",
    "\n",
    "    def _get_layer_line(self,\n",
    "                        patch_box: Tuple[float, float, float, float],\n",
    "                        patch_angle: float,\n",
    "                        layer_name: str,\n",
    "                        return_token: bool = False) -> Optional[List[LineString]]:\n",
    "        \"\"\"\n",
    "        Retrieve the lines of a particular layer within the specified patch.\n",
    "        :param patch_box: Patch box defined as [x_center, y_center, height, width].\n",
    "        :param patch_angle: Patch orientation in degrees.\n",
    "        :param layer_name: name of map layer to be converted to binary map mask patch.\n",
    "        :return: List of LineString in a patch box.\n",
    "        \"\"\"\n",
    "        if layer_name not in self.map_api.non_geometric_line_layers:\n",
    "            raise ValueError(\"{} is not a line layer\".format(layer_name))\n",
    "\n",
    "        if layer_name is 'traffic_light':\n",
    "            return None\n",
    "\n",
    "        patch_x = patch_box[0]\n",
    "        patch_y = patch_box[1]\n",
    "\n",
    "        patch = self.get_patch_coord(patch_box, patch_angle)\n",
    "\n",
    "        line_list = []\n",
    "        line_tokens_list = []\n",
    "        valid_records = []\n",
    "        records = getattr(self.map_api, layer_name)\n",
    "        for record in records:\n",
    "            line = self.map_api.extract_line(record['line_token'])\n",
    "            if line.is_empty:  # Skip lines without nodes.\n",
    "                continue\n",
    "\n",
    "            new_line = line.intersection(patch)\n",
    "            if not new_line.is_empty:\n",
    "                new_line = affinity.rotate(\n",
    "                    new_line, -patch_angle, origin=(patch_x, patch_y), use_radians=False)\n",
    "                new_line = affinity.affine_transform(new_line,\n",
    "                                                     [1.0, 0.0, 0.0, 1.0, -patch_x, -patch_y])\n",
    "                line_list.append(new_line)\n",
    "                line_tokens_list.append(record['line_token'])\n",
    "                valid_records.append(record)\n",
    "\n",
    "        if return_token:\n",
    "            return line_list, line_tokens_list, valid_records\n",
    "\n",
    "        return line_list\n",
    "\n",
    "\n",
    "def to_patch_coord(new_polygon, patch_angle, patch_x, patch_y):\n",
    "    new_polygon = affinity.rotate(new_polygon, -patch_angle,\n",
    "                                  origin=(patch_x, patch_y), use_radians=False)\n",
    "    new_polygon = affinity.affine_transform(new_polygon,\n",
    "                                            [1.0, 0.0, 0.0, 1.0, -patch_x, -patch_y])\n",
    "    return new_polygon\n",
    "\n",
    "\n",
    "# utils\n",
    "def plot(polygon, buffer=1):\n",
    "    from descartes.patch import PolygonPath, PolygonPatch\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.add_patch(PolygonPatch(polygon.buffer(buffer),\n",
    "                 fill=False, fc='orange', ec='blue', alpha=0.5))\n",
    "    xy = np.array(polygon.buffer(buffer).exterior.coords)\n",
    "    ax.plot(xy[:, 0], xy[:, 1], 'o', color='orange')\n",
    "\n",
    "    ax.add_patch(PolygonPatch(polygon, fill=False,\n",
    "                 fc='red', ec='red', alpha=0.5))\n",
    "    xy = np.array(polygon.exterior.coords)\n",
    "    ax.plot(xy[:, 0], xy[:, 1], 'o', color='red')\n",
    "    fig.savefig('test_buffer.png', dpi=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_size = 3\n",
    "class VectorizeLocalMap_new(object):\n",
    "\n",
    "    def __init__(self,\n",
    "                 data_root=\"./datasets/nuScenes/\",\n",
    "                 line_classes=['road_divider', 'lane_divider'],\n",
    "                 ped_crossing_classes=['ped_crossing'],\n",
    "                 contour_classes=['road_segment', 'lane'],\n",
    "                 **kwargs):\n",
    "        '''\n",
    "        Args:\n",
    "            fixed_num = -1 : no fixed num\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.data_root = data_root\n",
    "        self.MAPS = ['boston-seaport', 'singapore-hollandvillage',\n",
    "                     'singapore-onenorth', 'singapore-queenstown']\n",
    "        self.line_classes = line_classes\n",
    "        self.ped_crossing_classes = ped_crossing_classes\n",
    "        self.contour_classes = contour_classes\n",
    "        self.patch_size = [100,100]\n",
    "        self.nusc_maps = {}\n",
    "        self.map_explorer = {}\n",
    "        for loc in self.MAPS:\n",
    "            self.nusc_maps[loc] = NuScenesMap(\n",
    "                dataroot=self.data_root, map_name=loc)\n",
    "            self.map_explorer[loc] = NuScenesMapExplorer(self.nusc_maps[loc])\n",
    "    \n",
    "    def get_global_patch(self, input_dict: dict):\n",
    "        # transform to global coordination\n",
    "        location = input_dict['location']\n",
    "        translation = input_dict['ego2global_translation']\n",
    "        rotation = Quaternion(input_dict['ego2global_rotation']).rotation_matrix\n",
    "\n",
    "        map_pose = translation[:2]\n",
    "        rotation = Quaternion(matrix=rotation)\n",
    "        patch_box = (map_pose[0], map_pose[1],\n",
    "                     self.patch_size[0]+pad_size, self.patch_size[1]+pad_size)\n",
    "        patch_angle = quaternion_yaw(rotation) / np.pi * 180\n",
    "\n",
    "        patch_params = (patch_box, patch_angle, location)\n",
    "\n",
    "        return patch_params\n",
    "    def filter_pts_inrange(self,pts):\n",
    "        max_x = self.patch_size[0] / 2\n",
    "        max_y = self.patch_size[1] / 2\n",
    "        mask = (-max_x < pts[...,0]) & (pts[..., 0] < max_x) & \\\n",
    "               (-max_y < pts[...,1]) & (pts[..., 1] < max_y)\n",
    "        pts = pts[mask]\n",
    "        # return none if nothing\n",
    "        return pts\n",
    "\n",
    "    def ego2lidar_and_filter(self, pts, input_dict, return_dim = 3):\n",
    "        \n",
    "        if 'l2e_r' in input_dict:\n",
    "            l2e_R = input_dict['l2e_r']\n",
    "            l2e_t = input_dict['l2e_t']\n",
    "        else:\n",
    "            l2e_R = Quaternion(input_dict['lidar2ego_rotation']).rotation_matrix\n",
    "            l2e_t = input_dict['lidar2ego_translation']\n",
    "        l2e = np.identity(4)\n",
    "        l2e[:3,:3] = np.array(l2e_R)\n",
    "        l2e[:3,3] = np.array(l2e_t)\n",
    "        # e2g_t = input_dict['ego2global_translation']\n",
    "        e2g_R = Quaternion(input_dict['ego2global_rotation'])\n",
    "        pts = torch.tensor(pts)\n",
    "        pts_z = torch.zeros_like(pts[:,0:1])\n",
    "        pts_t = torch.ones_like(pts[:,0:1])\n",
    "        pts = torch.cat([pts, pts_z, pts_t],dim=-1)\n",
    "        e2g_conpensate = Quaternion(axis=[0, 1, 0], radians=e2g_R.yaw_pitch_roll[1]) * \\\n",
    "                         Quaternion(axis=[1, 0, 0], radians=e2g_R.yaw_pitch_roll[2])\n",
    "        e2g_pitch_roll = e2g_conpensate.rotation_matrix\n",
    "        g2e_pitch_roll = np.linalg.inv(e2g_pitch_roll)\n",
    "        g2e_pitch_roll_4d = np.identity(4)\n",
    "        g2e_pitch_roll_4d[:3,:3] = g2e_pitch_roll\n",
    "        pts = torch.matmul(torch.tensor(g2e_pitch_roll_4d),pts.T).T\n",
    "        pts = torch.matmul(e2l,pts.T).T\n",
    "        pts = self.filter_pts_inrange(pts)\n",
    "        return np.array(pts[:,:return_dim])\n",
    "\n",
    "    def retrive_geom(self, patch_params):\n",
    "        '''\n",
    "            Get the geometric data.\n",
    "            Returns: dict\n",
    "        '''\n",
    "        patch_box, patch_angle, location = patch_params\n",
    "        geoms_dict = {}\n",
    "        centerline_records = []\n",
    "\n",
    "        layers = \\\n",
    "            self.line_classes + self.ped_crossing_classes + \\\n",
    "            self.contour_classes\n",
    "\n",
    "        layers = set(layers)\n",
    "        for layer_name in layers:\n",
    "\n",
    "            return_token = False\n",
    "\n",
    "            # retrive the geo\n",
    "            if layer_name in self.nusc_maps[location].non_geometric_line_layers:\n",
    "                geoms = self.map_explorer[location]._get_layer_line(\n",
    "                    patch_box, patch_angle, layer_name)\n",
    "            elif layer_name in self.nusc_maps[location].lookup_polygon_layers:\n",
    "                geoms = self.map_explorer[location]._get_layer_polygon(\n",
    "                    patch_box, patch_angle, layer_name)\n",
    "            else:\n",
    "                raise ValueError('{} is not a valid layer'.format(layer_name))\n",
    "\n",
    "            if geoms is None:\n",
    "                continue\n",
    "\n",
    "            # change every geoms set to list\n",
    "            if not isinstance(geoms, list):\n",
    "                geoms = [geoms, ]\n",
    "\n",
    "            geoms_dict[layer_name] = geoms\n",
    "\n",
    "        return geoms_dict\n",
    "\n",
    "    def __call__(self, input_dict):\n",
    "        print('new')\n",
    "        patch_params = self.get_global_patch(input_dict)\n",
    "        geoms_dict = self.retrive_geom(patch_params)\n",
    "\n",
    "        def sample_pts(pts):\n",
    "            line = LineString(pts)\n",
    "            distances = list(np.arange(1.0,\n",
    "                                       line.length, 1.0))\n",
    "            sampled_points = np.array([list(line.interpolate(distance).coords)\n",
    "                                       for distance in distances]).reshape(-1, 2)\n",
    "            sampled_points = self.ego2lidar_and_filter(sampled_points,input_dict)\n",
    "            return sampled_points\n",
    "\n",
    "        kpts = []\n",
    "        for k in geoms_dict:\n",
    "            for g in geoms_dict[k]:\n",
    "                if 'Polygon' in g.type:\n",
    "                    if 'Multi' in g.type:\n",
    "                        for _g in g:\n",
    "                            kpts.append(np.array(_g.exterior))\n",
    "                            kpts[-1] = sample_pts(kpts[-1])\n",
    "                    else:\n",
    "                        kpts.append(np.array(g.exterior))\n",
    "                        kpts[-1] = sample_pts(kpts[-1])\n",
    "                else:\n",
    "                    kpts.append(np.array(g))\n",
    "                    kpts[-1] = sample_pts(kpts[-1])\n",
    "\n",
    "        return kpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34154/3294748437.py:20: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  gt_list = nusc_map(input_dict)\n",
      "/tmp/ipykernel_34154/2638741340.py:139: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  for _g in g:\n",
      "/home/zhenglt/mmdev11/detr3d-dev11/projects/detr3d/vis_zlt.py:150: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(instances_3d['gt_labels_3d']).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n008-2018-09-18-14-35-12-0400__LIDAR_TOP__1537295816397605\n",
      "reference torch.Size([1900, 3])\n",
      "900 1600\n",
      "torch.Size([1, 1899, 3])\n",
      "frame: 30925\n",
      "new\n",
      "n008-2018-08-30-15-31-50-0400__LIDAR_TOP__1535657803550545\n",
      "reference torch.Size([2630, 3])\n",
      "900 1600\n",
      "torch.Size([1, 2629, 3])\n",
      "frame: 31669\n",
      "new\n",
      "n015-2018-09-25-13-17-43+0800__LIDAR_TOP__1537853040648000\n",
      "reference torch.Size([818, 3])\n",
      "900 1600\n",
      "torch.Size([1, 817, 3])\n",
      "frame: 33519\n",
      "new\n",
      "n015-2018-11-21-19-21-35+0800__LIDAR_TOP__1542799429797267\n",
      "reference torch.Size([616, 3])\n",
      "900 1600\n",
      "torch.Size([1, 615, 3])\n",
      "frame: 33683\n",
      "new\n",
      "n015-2018-11-21-19-21-35+0800__LIDAR_TOP__1542799417949014\n",
      "reference torch.Size([579, 3])\n",
      "900 1600\n",
      "torch.Size([1, 578, 3])\n",
      "frame: 33659\n",
      "new\n",
      "n008-2018-09-18-14-35-12-0400__LIDAR_TOP__1537295962798292\n",
      "reference torch.Size([1419, 3])\n",
      "900 1600\n",
      "torch.Size([1, 1418, 3])\n",
      "frame: 31113\n",
      "new\n",
      "n015-2018-10-08-15-44-23+0800__LIDAR_TOP__1538985027397601\n",
      "reference torch.Size([661, 3])\n",
      "900 1600\n",
      "torch.Size([1, 660, 3])\n",
      "frame: 33137\n",
      "new\n",
      "n015-2018-10-02-10-50-40+0800__LIDAR_TOP__1538448744447639\n",
      "reference torch.Size([1283, 3])\n",
      "900 1600\n",
      "torch.Size([1, 1282, 3])\n",
      "frame: 31889\n",
      "new\n",
      "n008-2018-08-31-11-37-23-0400__LIDAR_TOP__1535730405948483\n",
      "reference torch.Size([1618, 3])\n",
      "900 1600\n",
      "torch.Size([1, 1617, 3])\n",
      "frame: 30649\n",
      "new\n",
      "n015-2018-07-18-11-41-49+0800__LIDAR_TOP__1531885614049614\n",
      "reference torch.Size([2431, 3])\n",
      "900 1600\n",
      "torch.Size([1, 2430, 3])\n",
      "frame: 28332\n",
      "new\n",
      "n008-2018-08-01-15-16-36-0400__LIDAR_TOP__1533151522447088\n",
      "reference torch.Size([1967, 3])\n",
      "900 1600\n",
      "torch.Size([1, 1966, 3])\n",
      "frame: 28980\n",
      "new\n",
      "n015-2018-07-18-11-41-49+0800__LIDAR_TOP__1531885354699018\n",
      "reference torch.Size([1003, 3])\n",
      "900 1600\n",
      "torch.Size([1, 1002, 3])\n",
      "frame: 28240\n",
      "new\n",
      "n015-2018-09-25-13-17-43+0800__LIDAR_TOP__1537853023697876\n",
      "reference torch.Size([1337, 3])\n",
      "900 1600\n",
      "torch.Size([1, 1336, 3])\n",
      "frame: 33485\n",
      "new\n",
      "n008-2018-09-18-14-35-12-0400__LIDAR_TOP__1537295817897772\n",
      "reference torch.Size([2034, 3])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m map_points \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(map_points)\n\u001b[1;32m     26\u001b[0m \u001b[39m# print(map_points)\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m view_frame(token, map_points[:,:\u001b[39m3\u001b[39;49m])\n",
      "Cell \u001b[0;32mIn[43], line 24\u001b[0m, in \u001b[0;36mview_frame\u001b[0;34m(token, map_points)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m osp\u001b[39m.\u001b[39mexists(\u001b[39m'\u001b[39m\u001b[39mdebug/lyc_map/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mtoken):\n\u001b[1;32m     23\u001b[0m     os\u001b[39m.\u001b[39mmkdir(\u001b[39m'\u001b[39m\u001b[39mdebug/lyc_map/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mtoken)\n\u001b[0;32m---> 24\u001b[0m vis\u001b[39m.\u001b[39;49mvisualize_dataset_item(frame,[cat_instances],pts \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m,name_suffix\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdebug_pred\u001b[39;49m\u001b[39m'\u001b[39;49m, dirname\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdebug/lyc_map/\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m+\u001b[39;49mtoken)\n",
      "File \u001b[0;32m~/mmdev11/detr3d-dev11/projects/detr3d/vis_zlt.py:165\u001b[0m, in \u001b[0;36mvisualizer_zlt.visualize_dataset_item\u001b[0;34m(self, frame, batch_gt_instances_3d, pts, name_suffix, dirname)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mif\u001b[39;00m batch_gt_instances_3d \u001b[39m==\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     batch_gt_instances_3d \u001b[39m=\u001b[39m [\n\u001b[1;32m    163\u001b[0m         batch_data_samples\u001b[39m.\u001b[39mgt_instances_3d\n\u001b[1;32m    164\u001b[0m     ]\n\u001b[0;32m--> 165\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisualize(batch_gt_instances_3d, batch_input_metas,\n\u001b[1;32m    166\u001b[0m                 batch_inputs_dict\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39mimgs\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m), pts,\n\u001b[1;32m    167\u001b[0m                 name_suffix, dirname)\n",
      "File \u001b[0;32m~/mmdev11/detr3d-dev11/projects/detr3d/vis_zlt.py:194\u001b[0m, in \u001b[0;36mvisualizer_zlt.visualize\u001b[0;34m(self, instances_3d, img_meta, img, pts, name_suffix, dirname, pause)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[39mif\u001b[39;00m img_meta\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mlidar_path\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    193\u001b[0m     pc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_pts(img_meta, pts)\n\u001b[0;32m--> 194\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_bev(pc, instances_3d, dirname, filename)\n\u001b[1;32m    195\u001b[0m img_from_file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_imgs(img_paths)\n\u001b[1;32m    196\u001b[0m metacopy \u001b[39m=\u001b[39m copy(img_meta)\n",
      "File \u001b[0;32m~/mmdev11/detr3d-dev11/projects/detr3d/vis_zlt.py:439\u001b[0m, in \u001b[0;36mvisualizer_zlt.save_bev\u001b[0;34m(self, pts, instances_3d, dirname, out_name)\u001b[0m\n\u001b[1;32m    437\u001b[0m drawy \u001b[39m=\u001b[39m corners_x[j \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m:j \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m \u001b[39m+\u001b[39m \u001b[39m4\u001b[39m]\n\u001b[1;32m    438\u001b[0m pts \u001b[39m=\u001b[39m [(\u001b[39mint\u001b[39m(drawx[i]), \u001b[39mint\u001b[39m(drawy[i])) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m [\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m2\u001b[39m]]\n\u001b[0;32m--> 439\u001b[0m draw\u001b[39m.\u001b[39;49mpolygon(pts, outline\u001b[39m=\u001b[39;49mcolor, width\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m    440\u001b[0m \u001b[39m#(x0y0z0, x0y1z1, x1y1z1, x1y0z0)\u001b[39;00m\n\u001b[1;32m    441\u001b[0m (fx, fy), r \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_circle_from_diam(pts[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m], pts[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/mmdev11/lib/python3.8/site-packages/PIL/ImageDraw.py:277\u001b[0m, in \u001b[0;36mImageDraw.polygon\u001b[0;34m(self, xy, fill, outline, width)\u001b[0m\n\u001b[1;32m    273\u001b[0m draw\u001b[39m.\u001b[39mdraw\u001b[39m.\u001b[39mdraw_polygon(xy, mask_ink, \u001b[39m0\u001b[39m, width)\n\u001b[1;32m    275\u001b[0m mask\u001b[39m.\u001b[39mpaste(ink_im, mask\u001b[39m=\u001b[39mfill_im)\n\u001b[0;32m--> 277\u001b[0m im \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mnew(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mim\u001b[39m.\u001b[39;49msize)\n\u001b[1;32m    278\u001b[0m draw \u001b[39m=\u001b[39m Draw(im)\n\u001b[1;32m    279\u001b[0m draw\u001b[39m.\u001b[39mdraw\u001b[39m.\u001b[39mdraw_polygon(xy, ink, \u001b[39m0\u001b[39m, width)\n",
      "File \u001b[0;32m~/anaconda3/envs/mmdev11/lib/python3.8/site-packages/PIL/Image.py:2845\u001b[0m, in \u001b[0;36mnew\u001b[0;34m(mode, size, color)\u001b[0m\n\u001b[1;32m   2843\u001b[0m     im\u001b[39m.\u001b[39mpalette \u001b[39m=\u001b[39m ImagePalette\u001b[39m.\u001b[39mImagePalette()\n\u001b[1;32m   2844\u001b[0m     color \u001b[39m=\u001b[39m im\u001b[39m.\u001b[39mpalette\u001b[39m.\u001b[39mgetcolor(color)\n\u001b[0;32m-> 2845\u001b[0m \u001b[39mreturn\u001b[39;00m im\u001b[39m.\u001b[39m_new(core\u001b[39m.\u001b[39;49mfill(mode, size, color))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nusc_map = VectorizeLocalMap_new(data_root='data/nuscenes/')\n",
    "map_data = pandas.read_pickle('debug/lyc_map/map_data_upsampling.pkl')\n",
    "for token in map_data:\n",
    "    idx = token2idx[token]\n",
    "    # if token != 'a08cf86f5b2a4f5abdee5756820aa66f':\n",
    "    #     continue\n",
    "    frame = dataset[idx]\n",
    "    from pyquaternion import Quaternion\n",
    "    e2g = np.array(frame['data_samples'].metainfo['ego2global'])\n",
    "    rot = Quaternion(matrix=e2g[:3,:3],atol=1e-5)\n",
    "    l2e = np.array(frame['data_samples'].metainfo['lidar2ego'])\n",
    "    location = frame['data_samples'].metainfo['city_name']\n",
    "    input_dict = {\n",
    "        'l2e_r': l2e[:3,:3].tolist(),\n",
    "        'l2e_t': l2e[:3,3].tolist(),\n",
    "        'ego2global_rotation': rot.q,\n",
    "        'ego2global_translation': e2g[:2,3].tolist(),\n",
    "        'location': location\n",
    "    }\n",
    "    gt_list = nusc_map(input_dict)\n",
    "    l2e = np.array(frame['data_samples'].metainfo['lidar2ego'])\n",
    "    map_points = []\n",
    "    for gt in gt_list:\n",
    "        map_points.append(torch.tensor(gt))\n",
    "    map_points = torch.cat(map_points)\n",
    "    # print(map_points)\n",
    "    view_frame(token, map_points[:,:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmdev11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
